{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1663c5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization, Bidirectional, LeakyReLU\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard, CSVLogger\n",
    "\n",
    "import os\n",
    "\n",
    "# === Step 1: Load and preprocess ===\n",
    "df = pd.read_csv(\"acquiredDataset.csv\")\n",
    "\n",
    "# Compute band features\n",
    "df['alpha'] = (df['lowAlpha'] + df['highAlpha']) / 2\n",
    "df['beta'] = (df['lowBeta'] + df['highBeta']) / 2\n",
    "df = df[['alpha', 'beta', 'theta', 'delta', 'classification']]\n",
    "\n",
    "# === Step 2: Log-transform & MinMax scale ===\n",
    "features = df.drop(columns=['classification'])\n",
    "labels = df['classification']\n",
    "\n",
    "# Apply np.log1p\n",
    "features_log = np.log1p(features)\n",
    "\n",
    "# MinMax scaling\n",
    "scaler = MinMaxScaler()\n",
    "features_scaled = scaler.fit_transform(features_log)\n",
    "\n",
    "# Combine with label\n",
    "df_processed = pd.DataFrame(features_scaled, columns=features.columns)\n",
    "df_processed['classification'] = labels.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c7f11919",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Step 3: Generate sequences ===\n",
    "def generate_sequences(dataframe, seq_length):\n",
    "    sequences, labels = [], []\n",
    "    for i in range(len(dataframe) - seq_length):\n",
    "        seq = dataframe.iloc[i:i+seq_length, :-1].values\n",
    "        label = dataframe.iloc[i+seq_length-1, -1]\n",
    "        sequences.append(seq)\n",
    "        labels.append(label)\n",
    "    return np.array(sequences), np.array(labels)\n",
    "\n",
    "SEQ_LEN = 20\n",
    "X, y = generate_sequences(df_processed, SEQ_LEN)\n",
    "\n",
    "# === Step 4: Split into train/val/test (60/20/20) ===\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.3, random_state=42, stratify=y_temp) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b6a3ee45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/purab/.local/lib/python3.12/site-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# === Step 5: Model definition ===\n",
    "def build_advanced_lstm_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(128, return_sequences=True), input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Bidirectional(LSTM(64, return_sequences=False)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Dense(128, kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4)))\n",
    "    model.add(LeakyReLU(0.1))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Dense(64, kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4)))\n",
    "    model.add(LeakyReLU(0.1))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Dense(32, kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4)))\n",
    "    model.add(LeakyReLU(0.1))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = build_advanced_lstm_model((X_train.shape[1], X_train.shape[2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b727b448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 52ms/step - accuracy: 0.5953 - loss: 0.7790 - val_accuracy: 0.5695 - val_loss: 0.7400 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.7189 - loss: 0.6357 - val_accuracy: 0.5695 - val_loss: 0.7341 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.7513 - loss: 0.5763 - val_accuracy: 0.5695 - val_loss: 0.7237 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.7752 - loss: 0.5280 - val_accuracy: 0.5762 - val_loss: 0.6855 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.7473 - loss: 0.5656 - val_accuracy: 0.7074 - val_loss: 0.6625 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.7828 - loss: 0.5208 - val_accuracy: 0.6289 - val_loss: 0.6515 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.7834 - loss: 0.5087 - val_accuracy: 0.5852 - val_loss: 0.7010 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.8041 - loss: 0.5030 - val_accuracy: 0.7691 - val_loss: 0.5287 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.8076 - loss: 0.4891 - val_accuracy: 0.4765 - val_loss: 1.2687 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.8131 - loss: 0.4528 - val_accuracy: 0.8049 - val_loss: 0.4891 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8162 - loss: 0.4696 - val_accuracy: 0.5437 - val_loss: 1.3547 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.8361 - loss: 0.4362 - val_accuracy: 0.5067 - val_loss: 1.5309 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.8335 - loss: 0.4212 - val_accuracy: 0.5157 - val_loss: 1.8010 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8438 - loss: 0.4103 - val_accuracy: 0.6009 - val_loss: 0.9432 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m31/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8053 - loss: 0.4613\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8070 - loss: 0.4588 - val_accuracy: 0.4574 - val_loss: 1.7757 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.8524 - loss: 0.3937 - val_accuracy: 0.6121 - val_loss: 0.8538 - learning_rate: 2.0000e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.8483 - loss: 0.3944 - val_accuracy: 0.7702 - val_loss: 0.5846 - learning_rate: 2.0000e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.8591 - loss: 0.3697 - val_accuracy: 0.7635 - val_loss: 0.6338 - learning_rate: 2.0000e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.8583 - loss: 0.3773 - val_accuracy: 0.7904 - val_loss: 0.5038 - learning_rate: 2.0000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.8344 - loss: 0.4067 - val_accuracy: 0.8363 - val_loss: 0.4292 - learning_rate: 2.0000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.8516 - loss: 0.3732 - val_accuracy: 0.8229 - val_loss: 0.4941 - learning_rate: 2.0000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.8721 - loss: 0.3611 - val_accuracy: 0.8184 - val_loss: 0.4949 - learning_rate: 2.0000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.8452 - loss: 0.3877 - val_accuracy: 0.8262 - val_loss: 0.5034 - learning_rate: 2.0000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.8641 - loss: 0.3444 - val_accuracy: 0.8498 - val_loss: 0.4246 - learning_rate: 2.0000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.8759 - loss: 0.3451 - val_accuracy: 0.8419 - val_loss: 0.4533 - learning_rate: 2.0000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.8764 - loss: 0.3318 - val_accuracy: 0.8352 - val_loss: 0.4144 - learning_rate: 2.0000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.8659 - loss: 0.3444 - val_accuracy: 0.8520 - val_loss: 0.3916 - learning_rate: 2.0000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.8691 - loss: 0.3448 - val_accuracy: 0.8733 - val_loss: 0.3485 - learning_rate: 2.0000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.8708 - loss: 0.3429 - val_accuracy: 0.7848 - val_loss: 0.6060 - learning_rate: 2.0000e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.8809 - loss: 0.3250 - val_accuracy: 0.8285 - val_loss: 0.4387 - learning_rate: 2.0000e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.8773 - loss: 0.3297 - val_accuracy: 0.8352 - val_loss: 0.4419 - learning_rate: 2.0000e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.8719 - loss: 0.3337 - val_accuracy: 0.8229 - val_loss: 0.3992 - learning_rate: 2.0000e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8781 - loss: 0.3318\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.8782 - loss: 0.3318 - val_accuracy: 0.8038 - val_loss: 0.5320 - learning_rate: 2.0000e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.8973 - loss: 0.3064 - val_accuracy: 0.8778 - val_loss: 0.3269 - learning_rate: 4.0000e-05\n",
      "Epoch 35/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.8745 - loss: 0.3434 - val_accuracy: 0.8834 - val_loss: 0.3147 - learning_rate: 4.0000e-05\n",
      "Epoch 36/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.8731 - loss: 0.3274 - val_accuracy: 0.8879 - val_loss: 0.2830 - learning_rate: 4.0000e-05\n",
      "Epoch 37/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.8776 - loss: 0.3187 - val_accuracy: 0.8868 - val_loss: 0.2848 - learning_rate: 4.0000e-05\n",
      "Epoch 38/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.8896 - loss: 0.3029 - val_accuracy: 0.8857 - val_loss: 0.2832 - learning_rate: 4.0000e-05\n",
      "Epoch 39/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.8722 - loss: 0.3295 - val_accuracy: 0.8845 - val_loss: 0.2906 - learning_rate: 4.0000e-05\n",
      "Epoch 40/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.8783 - loss: 0.3094 - val_accuracy: 0.8823 - val_loss: 0.2848 - learning_rate: 4.0000e-05\n",
      "Epoch 41/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.8899 - loss: 0.2957 - val_accuracy: 0.8946 - val_loss: 0.2902 - learning_rate: 4.0000e-05\n",
      "Epoch 42/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.8907 - loss: 0.3110 - val_accuracy: 0.8879 - val_loss: 0.2914 - learning_rate: 4.0000e-05\n",
      "Epoch 43/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.8918 - loss: 0.2861 - val_accuracy: 0.8879 - val_loss: 0.2872 - learning_rate: 4.0000e-05\n",
      "Epoch 44/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.8787 - loss: 0.3282 - val_accuracy: 0.8834 - val_loss: 0.2857 - learning_rate: 4.0000e-05\n",
      "Epoch 45/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.8894 - loss: 0.3030 - val_accuracy: 0.8778 - val_loss: 0.2899 - learning_rate: 4.0000e-05\n",
      "Epoch 46/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8750 - loss: 0.3214\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.8752 - loss: 0.3212 - val_accuracy: 0.8823 - val_loss: 0.2929 - learning_rate: 4.0000e-05\n",
      "Epoch 47/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.8856 - loss: 0.3029 - val_accuracy: 0.8946 - val_loss: 0.2844 - learning_rate: 8.0000e-06\n",
      "Epoch 48/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.8798 - loss: 0.3215 - val_accuracy: 0.8969 - val_loss: 0.2746 - learning_rate: 8.0000e-06\n",
      "Epoch 49/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.9063 - loss: 0.2913 - val_accuracy: 0.8957 - val_loss: 0.2740 - learning_rate: 8.0000e-06\n",
      "Epoch 50/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.8846 - loss: 0.3187 - val_accuracy: 0.8969 - val_loss: 0.2728 - learning_rate: 8.0000e-06\n",
      "Epoch 51/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.8781 - loss: 0.3150 - val_accuracy: 0.9002 - val_loss: 0.2699 - learning_rate: 8.0000e-06\n",
      "Epoch 52/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.8830 - loss: 0.3174 - val_accuracy: 0.8969 - val_loss: 0.2725 - learning_rate: 8.0000e-06\n",
      "Epoch 53/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.8774 - loss: 0.3160 - val_accuracy: 0.8969 - val_loss: 0.2713 - learning_rate: 8.0000e-06\n",
      "Epoch 54/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.8715 - loss: 0.3412 - val_accuracy: 0.8957 - val_loss: 0.2718 - learning_rate: 8.0000e-06\n",
      "Epoch 55/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.8895 - loss: 0.3030 - val_accuracy: 0.8991 - val_loss: 0.2715 - learning_rate: 8.0000e-06\n",
      "Epoch 56/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8879 - loss: 0.3031\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.8880 - loss: 0.3029 - val_accuracy: 0.8991 - val_loss: 0.2702 - learning_rate: 8.0000e-06\n",
      "Epoch 57/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.8956 - loss: 0.3055 - val_accuracy: 0.8980 - val_loss: 0.2692 - learning_rate: 1.6000e-06\n",
      "Epoch 58/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.8927 - loss: 0.2975 - val_accuracy: 0.8957 - val_loss: 0.2681 - learning_rate: 1.6000e-06\n",
      "Epoch 59/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.8845 - loss: 0.2976 - val_accuracy: 0.8946 - val_loss: 0.2682 - learning_rate: 1.6000e-06\n",
      "Epoch 60/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.8870 - loss: 0.2967 - val_accuracy: 0.8969 - val_loss: 0.2679 - learning_rate: 1.6000e-06\n",
      "Epoch 61/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8851 - loss: 0.3039\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.8852 - loss: 0.3040 - val_accuracy: 0.9002 - val_loss: 0.2678 - learning_rate: 1.6000e-06\n",
      "Epoch 62/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.8764 - loss: 0.3266 - val_accuracy: 0.8980 - val_loss: 0.2677 - learning_rate: 1.0000e-06\n",
      "Epoch 63/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.8849 - loss: 0.2937 - val_accuracy: 0.8946 - val_loss: 0.2675 - learning_rate: 1.0000e-06\n",
      "Epoch 64/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.8859 - loss: 0.3015 - val_accuracy: 0.8969 - val_loss: 0.2675 - learning_rate: 1.0000e-06\n",
      "Epoch 65/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.8867 - loss: 0.3050 - val_accuracy: 0.8991 - val_loss: 0.2674 - learning_rate: 1.0000e-06\n",
      "Epoch 66/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.8765 - loss: 0.3212 - val_accuracy: 0.9002 - val_loss: 0.2673 - learning_rate: 1.0000e-06\n",
      "Epoch 67/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.8760 - loss: 0.3322 - val_accuracy: 0.8969 - val_loss: 0.2671 - learning_rate: 1.0000e-06\n",
      "Epoch 68/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.8977 - loss: 0.2821 - val_accuracy: 0.8980 - val_loss: 0.2673 - learning_rate: 1.0000e-06\n",
      "Epoch 69/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.8808 - loss: 0.3013 - val_accuracy: 0.8969 - val_loss: 0.2675 - learning_rate: 1.0000e-06\n",
      "Epoch 70/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.8720 - loss: 0.2948 - val_accuracy: 0.8969 - val_loss: 0.2670 - learning_rate: 1.0000e-06\n",
      "Epoch 71/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.9000 - loss: 0.2973 - val_accuracy: 0.8957 - val_loss: 0.2669 - learning_rate: 1.0000e-06\n",
      "Epoch 72/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.8952 - loss: 0.2916 - val_accuracy: 0.8969 - val_loss: 0.2673 - learning_rate: 1.0000e-06\n",
      "Epoch 73/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.8792 - loss: 0.3094 - val_accuracy: 0.8980 - val_loss: 0.2672 - learning_rate: 1.0000e-06\n",
      "Epoch 74/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.8881 - loss: 0.3065 - val_accuracy: 0.8980 - val_loss: 0.2678 - learning_rate: 1.0000e-06\n",
      "Epoch 75/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.8863 - loss: 0.3067 - val_accuracy: 0.8969 - val_loss: 0.2679 - learning_rate: 1.0000e-06\n",
      "Epoch 76/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.8960 - loss: 0.3015 - val_accuracy: 0.8980 - val_loss: 0.2679 - learning_rate: 1.0000e-06\n",
      "Epoch 77/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.8901 - loss: 0.2921 - val_accuracy: 0.8957 - val_loss: 0.2674 - learning_rate: 1.0000e-06\n",
      "Epoch 78/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.8875 - loss: 0.3030 - val_accuracy: 0.8957 - val_loss: 0.2675 - learning_rate: 1.0000e-06\n",
      "Epoch 79/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.8822 - loss: 0.3066 - val_accuracy: 0.8969 - val_loss: 0.2675 - learning_rate: 1.0000e-06\n",
      "Epoch 80/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.8854 - loss: 0.2917 - val_accuracy: 0.8969 - val_loss: 0.2672 - learning_rate: 1.0000e-06\n",
      "Epoch 81/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8985 - loss: 0.3067 - val_accuracy: 0.8969 - val_loss: 0.2671 - learning_rate: 1.0000e-06\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# === Step 6: Callbacks ===\n",
    "def create_callbacks():\n",
    "    os.makedirs(\"models\", exist_ok=True)\n",
    "    return [\n",
    "        EarlyStopping(monitor='val_accuracy', patience=30, restore_best_weights=True),\n",
    "        ModelCheckpoint(\"models/best_classifier.keras\", save_best_only=True, monitor='val_accuracy', mode='max'),\n",
    "        ReduceLROnPlateau(monitor='val_accuracy', factor=0.2, patience=5, min_lr=1e-6, verbose=1),\n",
    "        TensorBoard(log_dir='logs'),\n",
    "        CSVLogger(\"training_log.csv\")\n",
    "    ]\n",
    "\n",
    "# === Step 7: Train the model ===\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=create_callbacks(),\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9e99e559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step\n",
      "\n",
      "Test Accuracy: 0.8842530282637954\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.92      0.90       423\n",
      "           1       0.89      0.84      0.86       320\n",
      "\n",
      "    accuracy                           0.88       743\n",
      "   macro avg       0.88      0.88      0.88       743\n",
      "weighted avg       0.88      0.88      0.88       743\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(int).flatten()\n",
    "\n",
    "print(\"\\nTest Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60184e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
